{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_embeddings.ipynb","provenance":[{"file_id":"10zPuHhJVLqQEkiQ9TOVjShX5rL9OjxQh","timestamp":1636716909916},{"file_id":"1MoeDmAaLaPv9i1MsZOpeGb2ZwvQPQK8F","timestamp":1619184317310}],"collapsed_sections":[],"authorship_tag":"ABX9TyOz2sQG4AqoStr9CVERfvjG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0daa5c24a27e4db6991bc4cc71bac82d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68359e5056d342deb8c8aab28392c34d","IPY_MODEL_d672e333ebb74832aeb9bfc3f8d26d85","IPY_MODEL_a81e4dcf32fe4df8a23a0829a4fdcb88"],"layout":"IPY_MODEL_9af2c0d8353142c698bb1026e4c59ccd"}},"68359e5056d342deb8c8aab28392c34d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_114b18c8f34e4397a80274d0f0423f65","placeholder":"​","style":"IPY_MODEL_f2c382a4663b4f25b9d17e18bd236d82","value":"Downloading: 100%"}},"d672e333ebb74832aeb9bfc3f8d26d85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd2d278f35cd492eb67b513a3a914120","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b61bd282150f4fafbae272bb90230bda","value":231508}},"a81e4dcf32fe4df8a23a0829a4fdcb88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbbf015204c84a7093ad44748e6e14bb","placeholder":"​","style":"IPY_MODEL_81ca504b399946c9bb752c736cb1a060","value":" 226k/226k [00:00&lt;00:00, 704kB/s]"}},"9af2c0d8353142c698bb1026e4c59ccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"114b18c8f34e4397a80274d0f0423f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c382a4663b4f25b9d17e18bd236d82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd2d278f35cd492eb67b513a3a914120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b61bd282150f4fafbae272bb90230bda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbbf015204c84a7093ad44748e6e14bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ca504b399946c9bb752c736cb1a060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"izA3-6kffbdT"},"source":["# Используем BERT впервые\n","\n","Источник: [Jay Alamar](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)\n","\n","\n","BERT --  это большой энкодер из трансформера, обученный предсказывать пропущенные слова в тексте.\n","\n","<img src=\"https://www.researchgate.net/profile/Faiza_Khattak/publication/332543716/figure/fig3/AS:796161606684672@1566831127392/BERT-model-10-Taking-masked-input-and-outputting-the-masked-words.ppm\" />\n","\n","DistilBERT -- \"облегченная\" версия BERT, о которой больше расскажут в следующих лекциях.\n","\n","В этом семинаре мы будем использовать BERT (или DistilBERT), чтобы получить векторные представления для текста, а затем -- простую модель, чтобы решить задачу классификации. В качестве классификации мы будем решать задачу определения тональности.\n","\n","### Models: Sentence Sentiment Classification\n","\n","Так как мы занимаемся transfer learning, наша модель будет состоять из двух частей:\n","\n","* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n","* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n","\n","The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n","\n","\n","<img src=\"https://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\" />\n","\n","## Dataset\n","The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n","\n","\n","<table class=\"features-table\">\n","  <tr>\n","    <th class=\"mdc-text-light-green-600\">\n","    sentence\n","    </th>\n","    <th class=\"mdc-text-purple-600\">\n","    label\n","    </th>\n","  </tr>\n","  <tr>\n","    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n","      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n","    </td>\n","    <td class=\"mdc-bg-purple-50\">\n","      1\n","    </td>\n","  </tr>\n","  <tr>\n","    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n","      apparently reassembled from the cutting room floor of any given daytime soap\n","    </td>\n","    <td class=\"mdc-bg-purple-50\">\n","      0\n","    </td>\n","  </tr>\n","  <tr>\n","    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n","      they presume their audience won't sit still for a sociology lesson\n","    </td>\n","    <td class=\"mdc-bg-purple-50\">\n","      0\n","    </td>\n","  </tr>\n","  <tr>\n","    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n","      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n","    </td>\n","    <td class=\"mdc-bg-purple-50\">\n","      1\n","    </td>\n","  </tr>\n","  <tr>\n","    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n","      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n","    </td>\n","    <td class=\"mdc-bg-purple-50\">\n","      1\n","    </td>\n","  </tr>\n","</table>\n","\n","## Устанавливаем библиотеку transformers от huggingface"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"To9ENLU90WGl","executionInfo":{"elapsed":12860,"status":"ok","timestamp":1633546526965,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"0d22ef20-a78b-4e57-b80f-85f548053824"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.0 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.1 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.2.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"]}]},{"cell_type":"code","metadata":{"id":"fvFvBLJV0Dkv"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQ-42fh0hjsF"},"source":["## Данные"]},{"cell_type":"code","metadata":{"id":"cyoj29J24hPX"},"source":["df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"_8hu_H0-xnrd","executionInfo":{"elapsed":13,"status":"ok","timestamp":1633547297049,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"fa4c1119-ccdc-46d0-d24f-59ad646aad75"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a stirring , funny and finally transporting re...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>apparently reassembled from the cutting room f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>they presume their audience wo n't sit still f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>this is a visually stunning rumination on love...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>jonathan parker 's bartleby should have been t...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0  1\n","0  a stirring , funny and finally transporting re...  1\n","1  apparently reassembled from the cutting room f...  0\n","2  they presume their audience wo n't sit still f...  0\n","3  this is a visually stunning rumination on love...  1\n","4  jonathan parker 's bartleby should have been t...  1"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y2WRyXsUjT3q","executionInfo":{"elapsed":10,"status":"ok","timestamp":1633547298198,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"0e013f86-08bf-468a-c60d-2a1aa934f89e"},"source":["df.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(6920, 2)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"dMVE3waNhuNj"},"source":["Возьмём первые 2,000."]},{"cell_type":"code","metadata":{"id":"gTM3hOHW4hUY"},"source":["batch_1 = df[:2000]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PRc2L89hh1Tf"},"source":["Баланс классов:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGvcfcCP5xpZ","executionInfo":{"elapsed":9,"status":"ok","timestamp":1633547301766,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"2ba5da6d-19b9-48c6-c04f-d20cd6dc060f"},"source":["batch_1[1].value_counts()"],"execution_count":null,"outputs":[{"data":{"text/plain":["1    1041\n","0     959\n","Name: 1, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"7_MO08_KiAOb"},"source":["## Loading the Pre-trained BERT model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247,"referenced_widgets":["0daa5c24a27e4db6991bc4cc71bac82d","68359e5056d342deb8c8aab28392c34d","d672e333ebb74832aeb9bfc3f8d26d85","a81e4dcf32fe4df8a23a0829a4fdcb88","9af2c0d8353142c698bb1026e4c59ccd","114b18c8f34e4397a80274d0f0423f65","f2c382a4663b4f25b9d17e18bd236d82","bd2d278f35cd492eb67b513a3a914120","b61bd282150f4fafbae272bb90230bda","cbbf015204c84a7093ad44748e6e14bb","81ca504b399946c9bb752c736cb1a060","f81262ca3d9b4177acf54e936a458fc2","b1882fe782a8446a9cabe167ecacdc82","4ec1b0d0c9934567b817e86f3d69fbd1","725e5684be3441bd98fdae769be43d59"]},"id":"q1InADgf5xm2","executionInfo":{"elapsed":15570,"status":"ok","timestamp":1633547319050,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"f94ff12e-2e59-49b9-8b94-191ffe1b3ee3"},"source":["# For DistilBERT:\n","model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","\n","## Want BERT instead of distilBERT? Uncomment the following line:\n","#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n","\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0daa5c24a27e4db6991bc4cc71bac82d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f81262ca3d9b4177acf54e936a458fc2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1882fe782a8446a9cabe167ecacdc82","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ec1b0d0c9934567b817e86f3d69fbd1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"725e5684be3441bd98fdae769be43d59","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"markdown","metadata":{"id":"lZDBMn3wiSX6"},"source":["Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n","\n","\n","### Токенизация\n","Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with.\n"]},{"cell_type":"code","metadata":{"id":"Dg82ndBA5xlN"},"source":["tokenized = batch_1[0].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPdPH9Y308-K","executionInfo":{"elapsed":609,"status":"ok","timestamp":1619193251025,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"0ae2ac19-af4f-4d54-948e-d945e25c16a4"},"source":["tokenized[:5] # индексы токенов в классе токенизатора"],"execution_count":null,"outputs":[{"data":{"text/plain":["0    [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n","1    [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n","2    [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n","3    [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n","4    [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n","Name: 0, dtype: object"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"wyZrDSD4C0ju"},"source":["В начало каждого текста добавляется токен `[CLS]`. Его эмбеддинг будет служить эмбеддингом всего текста при классификации текстов."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NzxDwhclkOa5","executionInfo":{"elapsed":583,"status":"ok","timestamp":1619193271047,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"7569ac26-0824-42b3-ad1e-db8160a03786"},"source":["df.iloc[0][0]"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films'"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kywVGVJklP9W","executionInfo":{"elapsed":2218,"status":"ok","timestamp":1619193284077,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"32cbf873-b45c-46a3-f509-b5c691b1c425"},"source":["tokenizer.decode(tokenized[0])"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] a stirring, funny and finally transporting re imagining of beauty and the beast and 1930s horror films [SEP]'"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"l-3PZrUokjVD","outputId":"04248c2e-16d8-43cf-89bb-27d73c168660"},"source":["tokenizer.vocab['[CLS]']"],"execution_count":null,"outputs":[{"data":{"text/plain":["101"]},"execution_count":113,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"FwNLwWrlCSfj"},"source":["Особенности токенизации: [WordPiece tokenization](https://medium.com/@makcedward/how-subword-helps-on-your-nlp-model-83dd1b836f46). Это эффективный способ бороться с OOV словами: если слова нет в словаре, разбей его на знакомые кусочки."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuLc2gUehMFD","executionInfo":{"elapsed":577,"status":"ok","timestamp":1619193312860,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"dfa4810c-02ab-42e5-b0fe-a98794d22d62"},"source":["tokenizer.wordpiece_tokenizer.tokenize('interesting work')"],"execution_count":null,"outputs":[{"data":{"text/plain":["['interesting', 'work']"]},"execution_count":13,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWpbKM0plrXD","executionInfo":{"elapsed":610,"status":"ok","timestamp":1619193324683,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"b2d3f562-c7b3-4300-bde4-feda23698f33"},"source":["tokenizer.wordpiece_tokenizer.tokenize('pythonista')"],"execution_count":null,"outputs":[{"data":{"text/plain":["['python', '##ista']"]},"execution_count":14,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idWsg0rMmFF7","executionInfo":{"elapsed":635,"status":"ok","timestamp":1619193864596,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"98ac9625-7cf5-4b55-d064-7f2a67f58800"},"source":["tokenizer.wordpiece_tokenizer.tokenize('cowork')"],"execution_count":null,"outputs":[{"data":{"text/plain":["['cow', '##or', '##k']"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"mHwjUwYgi-uL"},"source":["<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n","\n","### Padding\n","Выравниваем предложения по длине с помощью нулевых токенов."]},{"cell_type":"code","metadata":{"id":"URn-DWJt5xhP"},"source":["# находим самое длинное предложение\n","max_len = 0\n","for i in tokenized.values:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","\n","# заполняем обучающие данные, где не хватает длины до максимума -- добавляем нули\n","padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdi7uXo95xeq","executionInfo":{"elapsed":16,"status":"ok","timestamp":1633547320415,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"afd34acd-c311-4144-d144-12bfb5fa7de2"},"source":["np.array(padded).shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(2000, 59)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ur9hUNBOj5Zi","executionInfo":{"elapsed":11,"status":"ok","timestamp":1633547320416,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"b01be524-341a-4061-af3f-7f18ad187efa"},"source":["padded[0]"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([  101,  1037, 18385,  1010,  6057,  1998,  2633, 18276,  2128,\n","       16603,  1997,  5053,  1998,  1996,  6841,  1998,  5687,  5469,\n","        3152,   102,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"d4_hdzcDj_re","executionInfo":{"elapsed":681,"status":"ok","timestamp":1619194008869,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"0ead559a-ac7f-465a-8e17-643d69307964"},"source":["tokenizer.ids_to_tokens[0]"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[PAD]'"]},"execution_count":20,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"sDZBsYSDjzDV"},"source":["### Masking\n","\n","Теперь создаём отдельную переменную, чтобы сказать берту, что надо игнорировать паддинг при подсчёте attention."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4K_iGRNa_Ozc","executionInfo":{"elapsed":10,"status":"ok","timestamp":1633547320637,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"3efb2cd2-1399-40c9-fe42-5bbb6bedd331"},"source":["attention_mask = np.where(padded != 0, 1, 0)\n","attention_mask.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(2000, 59)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwX4c8D5nK07","executionInfo":{"elapsed":214,"status":"ok","timestamp":1633547345891,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"4d414138-a557-4e6d-f97b-2ed7b1339cd5"},"source":["len(tokenized[0])"],"execution_count":null,"outputs":[{"data":{"text/plain":["20"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BufTWLdDqR7F","executionInfo":{"elapsed":201,"status":"ok","timestamp":1633547403411,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"209f0051-cfff-4234-a219-d175ceece135"},"source":["attention_mask[0]"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"jK-CQB9-kN99"},"source":["## Используем BERT\n","\n","`model()` прогоняет предложения через BERT."]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"39UVjAV56PJz","executionInfo":{"elapsed":13738,"status":"ok","timestamp":1633547608140,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"43539882-d65f-4950-8897-e5c8ee76d30a"},"source":["input_ids = torch.tensor(padded[:100])  \n","attention_mask = torch.tensor(attention_mask[:100])\n","\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask)"],"execution_count":null,"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-592737a6eacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             )\n\u001b[1;32m    330\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"FoCep_WVuB3v"},"source":["Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n","\n","<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n","\n","Берём оттуда только представления первого токена -- `[CLS]`. Это представление и будет нашими признаками."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FugJuHfGllRc","executionInfo":{"elapsed":8,"status":"ok","timestamp":1633547630253,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"a24af50c-3eab-4bd7-d158-7bedc3aeee55"},"source":["last_hidden_states[0][0]"],"execution_count":null,"outputs":[{"data":{"text/plain":["tensor([[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n","        [-0.2471,  0.2468,  0.1008,  ..., -0.1631,  0.9349, -0.0715],\n","        [ 0.0558,  0.3573,  0.4140,  ..., -0.2430,  0.1770, -0.5080],\n","        ...,\n","        [-0.0165,  0.1179,  0.3512,  ..., -0.2401,  0.2722, -0.1750],\n","        [ 0.0961,  0.0667,  0.3147,  ..., -0.3277,  0.3556, -0.2135],\n","        [ 0.0454,  0.0519,  0.3168,  ..., -0.2880,  0.1844, -0.1042]])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":162},"id":"7HRfbCvXBE3l","executionInfo":{"elapsed":295,"status":"error","timestamp":1633547621425,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"a66074b3-1fc9-4ad5-bf61-32dfdd55ecab"},"source":["last_hidden_states."],"execution_count":null,"outputs":[{"data":{"text/plain":["BaseModelOutput([('last_hidden_state',\n","                  tensor([[[-2.1593e-01, -1.4029e-01,  8.3112e-03,  ..., -1.3695e-01,\n","                             5.8670e-01,  2.0113e-01],\n","                           [-2.4709e-01,  2.4680e-01,  1.0081e-01,  ..., -1.6310e-01,\n","                             9.3485e-01, -7.1519e-02],\n","                           [ 5.5811e-02,  3.5733e-01,  4.1397e-01,  ..., -2.4296e-01,\n","                             1.7697e-01, -5.0803e-01],\n","                           ...,\n","                           [-1.6488e-02,  1.1792e-01,  3.5116e-01,  ..., -2.4005e-01,\n","                             2.7221e-01, -1.7501e-01],\n","                           [ 9.6078e-02,  6.6731e-02,  3.1472e-01,  ..., -3.2767e-01,\n","                             3.5559e-01, -2.1347e-01],\n","                           [ 4.5444e-02,  5.1928e-02,  3.1680e-01,  ..., -2.8795e-01,\n","                             1.8443e-01, -1.0417e-01]],\n","                  \n","                          [[-1.7263e-01, -1.4476e-01,  2.2343e-03,  ..., -1.7443e-01,\n","                             2.1386e-01,  3.7197e-01],\n","                           [ 2.1854e-03,  1.6837e-01,  1.2687e-01,  ..., -1.8882e-01,\n","                            -1.9514e-02, -2.8253e-02],\n","                           [ 2.5667e-02, -2.4577e-01,  7.1661e-02,  ..., -4.3394e-01,\n","                             1.6224e-01,  1.3260e-02],\n","                           ...,\n","                           [ 5.0452e-02, -4.9347e-02,  4.6318e-02,  ..., -4.4811e-02,\n","                            -5.3987e-02,  3.1363e-01],\n","                           [-2.1280e-01, -1.9065e-01, -2.1530e-02,  ...,  1.3922e-02,\n","                            -2.4331e-01, -2.0239e-02],\n","                           [-1.3104e-01, -1.6927e-01,  1.0187e-01,  ..., -8.5943e-02,\n","                            -1.7696e-01, -8.7220e-02]],\n","                  \n","                          [[-5.0633e-02,  7.2040e-02, -2.9597e-02,  ..., -7.1490e-02,\n","                             7.1852e-01,  2.6225e-01],\n","                           [ 5.3613e-02,  3.1362e-01, -5.9799e-02,  ...,  2.6764e-01,\n","                             8.6677e-01, -3.3799e-01],\n","                           [ 3.7924e-01,  2.7924e-01,  2.3735e-02,  ...,  3.4320e-02,\n","                             4.2719e-01,  1.6803e-01],\n","                           ...,\n","                           [ 2.3144e-01,  2.4272e-01,  1.0302e-01,  ..., -8.3995e-02,\n","                             2.3223e-01,  6.1269e-02],\n","                           [ 7.4137e-02,  4.6470e-02,  1.0835e-01,  ...,  5.3030e-02,\n","                             1.9706e-01,  2.3326e-02],\n","                           [ 1.0425e-01,  3.1385e-01,  7.6784e-02,  ..., -3.0116e-02,\n","                             1.0518e-01, -7.7977e-02]],\n","                  \n","                          ...,\n","                  \n","                          [[-2.3087e-01,  3.4341e-02, -3.1309e-01,  ..., -9.8128e-02,\n","                             5.1498e-01,  5.2849e-01],\n","                           [-4.7169e-01,  3.2504e-01, -7.3040e-01,  ...,  2.2648e-01,\n","                             6.5207e-01, -1.8083e-01],\n","                           [ 1.0992e-01, -6.5538e-02,  1.8086e-01,  ...,  2.9016e-01,\n","                             2.8564e-01, -2.7579e-01],\n","                           ...,\n","                           [-1.9427e-01, -9.8246e-02, -5.4540e-02,  ...,  8.4628e-02,\n","                             1.8052e-01,  6.4259e-02],\n","                           [-2.5677e-01,  8.9217e-02,  1.0204e-01,  ..., -1.5295e-01,\n","                             2.4789e-01, -8.2899e-03],\n","                           [-1.4211e-01,  1.2870e-01, -1.4655e-01,  ..., -9.1835e-04,\n","                             2.2108e-01,  3.3312e-01]],\n","                  \n","                          [[ 1.4208e-01,  3.0318e-02, -7.3151e-03,  ...,  1.8330e-02,\n","                             3.6665e-01,  3.1708e-01],\n","                           [ 6.2170e-01, -1.4086e-02,  1.5164e-01,  ..., -3.0055e-03,\n","                             4.9630e-01,  4.5890e-01],\n","                           [ 6.0914e-01,  1.3065e-01,  3.7409e-01,  ..., -4.5016e-01,\n","                             1.2377e-01, -5.1245e-02],\n","                           ...,\n","                           [ 3.6771e-01,  1.3888e-01,  1.8114e-01,  ...,  2.8896e-02,\n","                            -3.2559e-02,  9.7118e-02],\n","                           [ 3.6584e-01,  4.0012e-01,  6.0273e-01,  ..., -1.3828e-01,\n","                            -3.0286e-01,  9.5916e-02],\n","                           [-1.0103e-02,  1.2956e-01,  3.0194e-01,  ..., -1.0462e-01,\n","                            -4.6423e-02, -2.1094e-02]],\n","                  \n","                          [[-3.6807e-01, -2.2164e-01, -8.1863e-02,  ..., -1.0451e-01,\n","                             3.5809e-01,  2.0583e-01],\n","                           [-4.1181e-01,  2.6174e-01, -2.0173e-01,  ...,  5.8972e-02,\n","                             4.5088e-01,  4.2893e-02],\n","                           [-7.2982e-02,  1.0889e-01, -8.5832e-02,  ..., -2.0718e-01,\n","                             1.1887e-01, -5.8308e-01],\n","                           ...,\n","                           [-1.6454e-01, -2.0521e-01,  3.3523e-02,  ...,  1.4509e-01,\n","                             2.2339e-02,  6.3318e-02],\n","                           [ 6.9994e-02, -5.3091e-02, -1.6743e-01,  ..., -6.1900e-02,\n","                             6.8378e-02, -8.2943e-02],\n","                           [ 1.6910e-01, -8.5018e-02,  1.2716e-01,  ..., -1.1845e-01,\n","                             3.3037e-01, -3.0190e-01]]]))])"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYlDYCz7oGPO","executionInfo":{"elapsed":653,"status":"ok","timestamp":1619194268277,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"881ac298-ba46-42fd-ed59-f282fffd9202"},"source":["last_hidden_states[0].shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["torch.Size([2000, 59, 768])"]},"execution_count":27,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"C9t60At16PVs"},"source":["features = last_hidden_states[0][:,0,:].numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTIhZduUodsY"},"source":["features.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VZVU66Gurr-"},"source":["Метки:"]},{"cell_type":"code","metadata":{"id":"JD3fX2yh6PTx"},"source":["labels = batch_1[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaoEvM2evRx1"},"source":["## LogReg на признаках из BERT\n","Разделим данные на обучающую и тестовую выборки."]},{"cell_type":"code","metadata":{"id":"ddAqbkoU6PP9"},"source":["train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCT9u8vAwnID"},"source":["We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG-EVWx4CzBc","executionInfo":{"elapsed":823,"status":"ok","timestamp":1619194309650,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"e79a3f83-c596-4f06-d10e-9ba917950ec4"},"source":["lr_clf = LogisticRegression()\n","lr_clf.fit(train_features, train_labels)"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"execution_count":32,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3rUMKuVgwzkY"},"source":["## Оцениваем результат\n","Accuracy на тесте:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCoyxRJ7ECTA","executionInfo":{"elapsed":453,"status":"ok","timestamp":1619194316916,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"c942b0f4-fd38-4722-bea4-e8e177fdae46"},"source":["lr_clf.score(test_features, test_labels)"],"execution_count":null,"outputs":[{"data":{"text/plain":["0.83"]},"execution_count":33,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"xDytulAEo2lY"},"source":["from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4h1HwmAXo6ag","executionInfo":{"elapsed":595,"status":"ok","timestamp":1619194320980,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"6da8662a-554e-4e4e-c7f1-13e41ae8fe68"},"source":["print(classification_report(lr_clf.predict(test_features), test_labels))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.83      0.82       235\n","           1       0.84      0.83      0.84       265\n","\n","    accuracy                           0.83       500\n","   macro avg       0.83      0.83      0.83       500\n","weighted avg       0.83      0.83      0.83       500\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"75oyhr3VxHoE"},"source":["Сравним с DummyClassifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnwgmqNG7i5l","executionInfo":{"elapsed":576,"status":"ok","timestamp":1619194327194,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"362c4f9b-5862-4b42-8623-ef873ef7aee0"},"source":["from sklearn.dummy import DummyClassifier\n","clf = DummyClassifier()\n","\n","scores = cross_val_score(clf, train_features, train_labels)\n","print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Dummy classifier score: 0.489 (+/- 0.04)\n"]}]},{"cell_type":"markdown","metadata":{"id":"7Lg4LOpoxSOR"},"source":["## Proper SST2 scores\n","For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n","\n","\n","And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue).\n","\n","При желании можно вернуться и заменить distilBERT на BERT, чтобы посмотреть какие результаты будут у него."]},{"cell_type":"code","metadata":{"id":"EJQuqV6cnWQu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkMAund-E2-o"},"source":["### Как использовать BERT в качестве эмбеддингов слов"]},{"cell_type":"code","metadata":{"id":"saaKUzQ-Bi1F"},"source":["s1 = 'i get my dollars at the bank'\n","s2 = 'the robber came into the bank'\n","s3 = 'i sit on the river bank'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hjh5GzHAKoPg"},"source":["Токенизируем"]},{"cell_type":"code","metadata":{"id":"tC-nCj94BthT"},"source":["s1_tok = tokenizer.encode(s1)\n","s2_tok = tokenizer.encode(s2)\n","s3_tok = tokenizer.encode(s3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C7bnntjsKqaK"},"source":["Получаем эмбеддинги"]},{"cell_type":"code","metadata":{"id":"XGiMsr34B9Ki"},"source":["with torch.no_grad():\n","    last_hidden_states1 = model(torch.tensor([s1_tok]))\n","    last_hidden_states2 = model(torch.tensor([s2_tok]))\n","    last_hidden_states3 = model(torch.tensor([s3_tok]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOAi_6IDKsuf"},"source":["Находим индексы интересующих нас токенов"]},{"cell_type":"code","metadata":{"id":"JRXAOM3NJVbc"},"source":["word_index = tokenizer.vocab['bank']\n","ind1, ind2, ind3 = s1_tok.index(word_index), s2_tok.index(word_index), s3_tok.index(word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1SlxbWmnCJs","executionInfo":{"elapsed":523,"status":"ok","timestamp":1619194792488,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"736daf2b-ad3b-4400-93e5-4193d7247710"},"source":["ind1, ind2, ind3"],"execution_count":null,"outputs":[{"data":{"text/plain":["(7, 6, 6)"]},"execution_count":50,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"7D1rvhCjKyZx"},"source":["Вот эмбеддинги, которые нам нужны"]},{"cell_type":"code","metadata":{"id":"u6VwsFz0DacM"},"source":["word1_emb = last_hidden_states1[0][:,ind1,:][0]\n","word2_emb = last_hidden_states2[0][:,ind2,:][0]\n","word3_emb = last_hidden_states3[0][:,ind3,:][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQ287iydEsGu"},"source":["Теперь посчитаем расстояние:"]},{"cell_type":"code","metadata":{"id":"uVki0iW0EWIJ"},"source":["from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2MySmk9Eaax","executionInfo":{"elapsed":664,"status":"ok","timestamp":1619194800879,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"cb594c2c-5d82-4b79-9d69-55f140aea67d"},"source":["# bank из первого предложения дальше всех от остальных\n","cosine_similarity([\n","    word1_emb.numpy(),\n","    word2_emb.numpy(),\n","    word3_emb.numpy()\n","])"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([[1.        , 0.8905865 , 0.72190803],\n","       [0.8905865 , 1.0000002 , 0.74510056],\n","       [0.72190803, 0.74510056, 0.99999994]], dtype=float32)"]},"execution_count":52,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"S-YcY2XLvzl_"},"source":["## Русский -- DeepPavlov"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["d723cfb91340485a9c22937ed479ba4d","0af1734212094e029903e39d70c9edc6","3f5485d21add4298aaf2e09878969233","56e583428bbf4662a7b51b24c8c09911"]},"id":"NgoR8STSv1Cn","executionInfo":{"elapsed":5228,"status":"ok","timestamp":1633546553498,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"f8c3bd26-2851-4471-bf3a-af3f52720ce3"},"source":["tokenizer = ppb.AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d723cfb91340485a9c22937ed479ba4d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0af1734212094e029903e39d70c9edc6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f5485d21add4298aaf2e09878969233","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.57M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56e583428bbf4662a7b51b24c8c09911","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["99db86b9066249d2a92ee8d9e4917e7f"]},"id":"akYc247Kv1to","executionInfo":{"elapsed":32779,"status":"ok","timestamp":1633546586275,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"c3093ee1-17f5-48f4-c615-cf29f7da6ad1"},"source":["model = ppb.AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99db86b9066249d2a92ee8d9e4917e7f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/678M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1mY1rTpwG9b","executionInfo":{"elapsed":265,"status":"ok","timestamp":1633546607985,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"990f23ae-412c-4da9-8475-42802b61541a"},"source":["tokenizer.tokenize('Русский текст')"],"execution_count":null,"outputs":[{"data":{"text/plain":["['русски', '##и', 'текст']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Law4gpUQx8Jj","executionInfo":{"elapsed":8,"status":"ok","timestamp":1633546616105,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"d4439af7-1de7-415a-f0bf-7adf6b725bbb"},"source":["tokenizer.tokenize('печенюшка')"],"execution_count":null,"outputs":[{"data":{"text/plain":["['печен', '##юшка']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"T3XF4jZyw7Zm"},"source":["#### Задание: классификация ленты"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"c7v8-wo_xA6Q","executionInfo":{"elapsed":27747,"status":"ok","timestamp":1602543341772,"user":{"displayName":"Мария Шеянова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjUBof_UDjR8wi8mc3l27fifrDxuKq5Eomre4PQ=s64","userId":"13414369628864094336"},"user_tz":-180},"outputId":"fc7cd4f5-2f52-474a-b17c-78b5a7a3c0c4"},"source":["! wget -O lenta-ru-train.csv https://www.dropbox.com/s/kdupcw1llbdbqwl/lenta-ru-train.csv?dl=0"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["--2020-10-12 22:55:14--  https://www.dropbox.com/s/kdupcw1llbdbqwl/lenta-ru-train.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.1, 2620:100:6021:1::a27d:4101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/kdupcw1llbdbqwl/lenta-ru-train.csv [following]\n","--2020-10-12 22:55:14--  https://www.dropbox.com/s/raw/kdupcw1llbdbqwl/lenta-ru-train.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com/cd/0/inline/BBJHIdeUzoLLbdWFvq2uNL109KjSUPLeuJctKxe-EY3vgpgAw4-60uqTbhxWyFxmb_zwkW7MXzghy3R3-TtzLKLFnG0g5ydk2MDa2_jjWjKtomJQjUhPtWkQs9mhb0al75U/file# [following]\n","--2020-10-12 22:55:15--  https://uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com/cd/0/inline/BBJHIdeUzoLLbdWFvq2uNL109KjSUPLeuJctKxe-EY3vgpgAw4-60uqTbhxWyFxmb_zwkW7MXzghy3R3-TtzLKLFnG0g5ydk2MDa2_jjWjKtomJQjUhPtWkQs9mhb0al75U/file\n","Resolving uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com (uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n","Connecting to uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com (uc876ff7315d53620cb0404a3223.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 517902316 (494M) [text/plain]\n","Saving to: ‘lenta-ru-train.csv’\n","\n","lenta-ru-train.csv  100%[===================>] 493.91M  22.6MB/s    in 23s     \n","\n","2020-10-12 22:55:41 (21.5 MB/s) - ‘lenta-ru-train.csv’ saved [517902316/517902316]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"N6ilhgEExLwu"},"source":["df_lenta = pd.read_csv('lenta-ru-train.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"d0jV4UZOxm_b","outputId":"d703305e-84a4-40d8-dedb-b88ebf5536ef"},"source":["df_lenta.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>topic</th>\n","      <th>topic_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Инфляция в январе 2006 года составит 2,6 процента</td>\n","      <td>Глава Росстата Владимир Соколин заявил, что в ...</td>\n","      <td>Экономика</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Никита Михалков учредил День российского кино</td>\n","      <td>У российских кинематографистов  появится новый...</td>\n","      <td>Культура</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Марко Матерацци вернется в строй к матчу с ЦСКА</td>\n","      <td>Медицинский штаб миланского \"Интера\" обнародов...</td>\n","      <td>Спорт</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Определены лауреаты премии \"Книга года\"</td>\n","      <td>Премии \"Книга года\" в 13 номинациях вручены на...</td>\n","      <td>Культура</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Гол Роналду со штрафного спас португальцев от ...</td>\n","      <td>Сборная Португалии сыграла вничью с командой И...</td>\n","      <td>Спорт</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  ... topic_label\n","0  Инфляция в январе 2006 года составит 2,6 процента  ...           0\n","1      Никита Михалков учредил День российского кино  ...           3\n","2    Марко Матерацци вернется в строй к матчу с ЦСКА  ...           1\n","3            Определены лауреаты премии \"Книга года\"  ...           3\n","4  Гол Роналду со штрафного спас португальцев от ...  ...           1\n","\n","[5 rows x 4 columns]"]},"execution_count":5,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"oMi0eEkgZDFz"},"source":["#### Сначала надо написать извлечение эмбеддингов из BERT для графы title"]},{"cell_type":"code","metadata":{"id":"2Z0iKqsuYu8o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIt_lip0Yvvc"},"source":["#### А потом использовать эти эмбеддинги для классификации"]},{"cell_type":"code","metadata":{"id":"9h7PKG0p-r_h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CWFsE8IZht_"},"source":["#### Альтернативное задание: классификация IMDB \n","\n"]},{"cell_type":"code","metadata":{"id":"IOzjF59yZyXb"},"source":["!wget https://raw.githubusercontent.com/devkosal/fastai_roberta/master/fastai_roberta_imdb/imdb_dataset.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxHndTibD4Ic"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLBGe9N7GKMQ"},"source":["Если осталось время:\n","- можно посмотреть на код трансформера ([ноубтук](https://colab.research.google.com/drive/13pcJhLtvnEu4DvJGJSrm6Pv3WEHUgXLe?usp=sharing))\n"]}]}