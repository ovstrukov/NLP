{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "https://github.com/maryszmary/nlp-netology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета RuTweetCorp ([источник](http://study.mokoron.com/)): [датасет](https://raw.githubusercontent.com/maryszmary/netology_nlp_2021/master/sem1/tweets_sentiment.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "# можно так, а можно руками перейти по ссылке\n",
    "!wget https://raw.githubusercontent.com/maryszmary/netology_nlp_2021/master/sem1/tweets_sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мыс на меня обиделась:(\\nя ей даже ничего не с...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аааааааааааааааааааа,не хочу на работу :(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У меня какой-то особенный вид ушей! :D, некото...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@simonovkon  он неплохой человек в жизни. Я ра...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Darina_Lo: Домааааа\\nЕхали на такси, пели ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  мыс на меня обиделась:(\\nя ей даже ничего не с...  negative\n",
       "1          аааааааааааааааааааа,не хочу на работу :(  negative\n",
       "2  У меня какой-то особенный вид ушей! :D, некото...  positive\n",
       "3  @simonovkon  он неплохой человек в жизни. Я ра...  negative\n",
       "4  RT @Darina_Lo: Домааааа\\nЕхали на такси, пели ...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834, 2)\n",
      "(170125,)\n",
      "(56709,)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мыс на меня обиделась:(\\nя ей даже ничего не сделала:(',\n",
       " 'аааааааааааааааааааа,не хочу на работу :(',\n",
       " 'У меня какой-то особенный вид ушей! :D, некоторые вакуумные наушники в моих ушах просто не держатся!',\n",
       " '@simonovkon  он неплохой человек в жизни. Я работала в шоу-бизе, со многими знакома. Встречаются очень хорошие люди. И не очень(((',\n",
       " 'RT @Darina_Lo: Домааааа\\nЕхали на такси, пели песни, отдыхали.\\nКричали на улице:)\\nМы настоящяя семья)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ngram_range` отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "* ngram_range=(1, 1) -- униграммы<br/>\n",
    "* ngram_range=(3, 3) -- триграммы<br/>\n",
    "* ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В `vec.vocabulary_` лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anastasia6888', 12155),\n",
       " ('на', 161715),\n",
       " ('свадьбу', 206766),\n",
       " ('не', 165357),\n",
       " ('пригласила', 193297),\n",
       " ('есть', 130512),\n",
       " ('люди', 154605),\n",
       " ('которые', 148504),\n",
       " ('ищут', 141940),\n",
       " ('работу', 199294),\n",
       " ('новогоднюю', 168614),\n",
       " ('ночь', 169253),\n",
       " ('интересно', 140653),\n",
       " ('ли', 152673),\n",
       " ('рекрутеры', 203024),\n",
       " ('им', 140062),\n",
       " ('сразу', 215322),\n",
       " ('отвечают', 175440),\n",
       " ('надо', 162383),\n",
       " ('будет', 108498)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry',),\n",
       " ('Potter',),\n",
       " ('and',),\n",
       " ('the',),\n",
       " ('Methods',),\n",
       " ('of',),\n",
       " ('Rationality',)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Harry Potter and the Methods of Rationality'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry', 'Potter'),\n",
       " ('Potter', 'and'),\n",
       " ('and', 'the'),\n",
       " ('the', 'Methods'),\n",
       " ('Methods', 'of'),\n",
       " ('of', 'Rationality')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry', 'Potter', 'and'),\n",
       " ('Potter', 'and', 'the'),\n",
       " ('and', 'the', 'Methods'),\n",
       " ('the', 'Methods', 'of'),\n",
       " ('Methods', 'of', 'Rationality')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry', 'Potter', 'and', 'the', 'Methods'),\n",
       " ('Potter', 'and', 'the', 'Methods', 'of'),\n",
       " ('and', 'the', 'Methods', 'of', 'Rationality')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, solver='liblinear')\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.76     28223\n",
      "    positive       0.77      0.77      0.77     28486\n",
      "\n",
      "    accuracy                           0.77     56709\n",
      "   macro avg       0.77      0.77      0.77     56709\n",
      "weighted avg       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.57     18239\n",
      "    positive       0.82      0.61      0.70     38470\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.64      0.67      0.63     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26706\n",
      "    positive       0.79      0.75      0.77     30003\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, solver='liblinear')\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось чуть хуже :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем разные аргументы `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мыс', 'на', 'меня', 'обиделась:(', 'я', 'ей', 'даже', 'ничего', 'не', 'сделала:(']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0060',\n",
       " '007',\n",
       " '0080',\n",
       " '008ge0nygh',\n",
       " '008novublr',\n",
       " '009_panda',\n",
       " '00_anita_00',\n",
       " '00_elenka',\n",
       " '00_kalashnikova',\n",
       " '00_katusha',\n",
       " '00_orekhova',\n",
       " '00c6a95bst',\n",
       " '00darya',\n",
       " '00dwpheuip',\n",
       " '00ennqulcp',\n",
       " '00gorbunova',\n",
       " '00kudrina',\n",
       " '00lg6bsnb8',\n",
       " '00okaay',\n",
       " '00pm']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем разбивать текст на слова с использованием регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно в NLP делают так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', '9.5', 'or', '525,600', 'my', 'favorite', 'number', '?']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'NLTKWordTokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 9.5 or 525,600 my favorite number ?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import toktok\n",
    "\n",
    "toktok = toktok.ToktokTokenizer()\n",
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "print (toktok.tokenize(text, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самые частотные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['мыс',\n",
       " 'на',\n",
       " 'меня',\n",
       " 'обиделась',\n",
       " 'я',\n",
       " 'ей',\n",
       " 'даже',\n",
       " 'ничего',\n",
       " 'не',\n",
       " 'сделала']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860),\n",
       " ('...', 22363),\n",
       " ('меня', 20656),\n",
       " ('у', 18928),\n",
       " ('как', 18280),\n",
       " ('так', 16839),\n",
       " ('D', 16575),\n",
       " ('это', 16542),\n",
       " ('мне', 16337),\n",
       " ('все', 14763),\n",
       " ('ты', 13412)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "\n",
    "# freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Ципфа\n",
    "Эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любом достаточно большом тексте ранг слова обратно пропорционален его частоте: $f = \\frac{a}{r}$\n",
    "\n",
    "$f$ – частота слова, $r$  – ранг слова, $a$  – параметр, для славянских языков – около 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "freqs = list(freq_dict.values())\n",
    "freqs = sorted(freqs, reverse = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[:300], range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Хипса\n",
    "\n",
    "С увеличением длины текста (количества токенов), количество слов увеличивается в соответствии с законом: $|V| = K*N^b$\n",
    "\n",
    "\n",
    "$N$  –  число токенов, $|V|$  – количество слов в словаре, $K, b$  –  параметры, обычно $K \\in [10,100], b \\in [0.4, 0.6]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▌                                                 | 75431/226834 [01:55<03:51, 654.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-1b488b84420a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mn_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mn_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cnt = Counter()\n",
    "n_words = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    cnt.update([token for token in tokens if token not in punctuation])\n",
    "    n_words.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEFCAYAAADJ4WEBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApF0lEQVR4nO3deXhV1bnH8e/LPMg8yRTmQUBlOCLOKCo4tGjVK05YS0Ut1ba2ttr2Xq120FrrValYnFCqIuJEVVQUwYkpIPOYMCXMECAYSMjw3j/OTu8RI4ScJGfI7/M8eXLOOnudvEvJ+WXvtffa5u6IiIiUVbVYFyAiIolNQSIiIlFRkIiISFQUJCIiEhUFiYiIRKVGrAsob82bN/eOHTvGugwRkYSyYMGCXe7eoix9ky5IOnbsSGpqaqzLEBFJKGa2sax9dWhLRESioiAREZGoKEhERCQqChIREYmKgkRERKKiIBERkagoSEREJCoKEhGRBFdQWMTUxVt4Zd6mmPz8pLsgUUSkqsjJK2ByagbPfr6ezD0H6Z/SmBGntMfMKrUOBYmISILZsT+XF77cwL/mbGLfwXxO6diEe7/XmyE9W1Z6iICCREQkYWzYlcO4mem8+dVm8ouKGNrreEaf05n+KU1iWpeCREQkzi3bvI+nZqXz3tKt1KxejatC7fjxWZ3p1Lx+rEsDFCQiInFrwcYsnpiRxszVOzmudg1uPrszo87sRMsGdWJd2jcoSERE4oi783naLh7/eC3zN+yhaf1a3DW0Bzec1oGGdWrGurwSKUhEROKAu/PJ6h08/nEaizL20qZRHf7n0l6MGNieerXi+6M6vqsTEUlyRUXOhyu28fjHaazYmk27JnX542V9uCrUjto1qse6vFJRkIiIxEBhkfPe0q2MnZHG6u376dS8Pn+98iQu69uWWjUS61pxBYmISCUqKCzinSVbeWLGWtJ35tC15XE8NqIvl57UhurVKv8akPKgIBERqQS5+YW8vWgz42ams2H3AXoe34B/XNufi/ocT7UEDZBiChIRkQqUk1fAxDkbeeazdez6+hC92zTknzcM4IITWiV8gBRTkIiIVIAtew/ywuwNTJqXwb6D+ZzVrTm3ntOF07s0i8kyJhVJQSIiUo5Wbs3m2c/X89ZXm3Hgwl6tGH12Z/rFeBmTinTUUwPM7Dkz22FmyyLa7jOzzWa2KPi6OOK1e8wszcxWm9nQiPYBZrY0eO1xCyLZzGqb2atB+1wz6xjR50YzWxt83VhuoxYRKWeLMvZy43PzuOixz3hnyRauH9SBWXcNZtz1A5I6RKB0eyQTgLHAi4e1P+ruf4tsMLNewAigN9AG+MjMurt7ITAOGA3MAd4DhgHTgFHAHnfvamYjgIeAq82sKXAvEAIcWGBmU919T5lGKiJSARZs3MP/frSGz9buokm9mtw1tAfXnZpC43q1Yl1apTlqkLj7p5F7CUcxHJjk7nnAejNLAwaa2QagobvPBjCzF4HLCAfJcOC+oP8UYGywtzIUmO7uWUGf6YTD55VS1iIiUiGKrwGZ8OUGFmzcQ/PjanHPRT259tQUGsTpMiYVKZo5kp+a2UggFfhlsKfQlvAeR7HMoC0/eHx4O8H3DAB3LzCzfUCzyPYS+nyDmY0mvLdDSkpKFEMSEfluhwqKeHvRZp6alU76zhw6NqvH7y85gWtPTYn7ZUwqUllHPg54gPAhpweAR4AfASWdiuBHaKeMfb7Z6D4eGA8QCoVK3EZEpKwOFRTx+sJMxs5IY/Peg/Q8vgFPXtefYb0T/xqQ8lCmIHH37cWPzexp4J3gaSbQPmLTdsCWoL1dCe2RfTLNrAbQCMgK2gcf1mdmWeoVESmL3PxCXp67ifGfrmNbdi592zfmj5f3YXD3Fkl3Cm80yhQkZtba3bcGTy8His/omgq8bGZ/JzzZ3g2Y5+6FZrbfzAYBc4GRwBMRfW4EZgNXAjPc3c3sA+DPZlZ8usOFwD1lqVdE5FgUB8i4Wens3J/HwE5NefCKEzlHAVKiowaJmb1CeM+guZllEj6TarCZ9SV8qGkDcAuAuy83s8nACqAAGBOcsQVwG+EzwOoSnmSfFrQ/C0wMJuazCJ/1hbtnmdkDwPxgu/uLJ95FRCpCXkEhk+Zl8I9P0tixP4/TOjdj7DX9OLVzs1iXFtfMPbmmFEKhkKempsa6DBFJIHkFhUxZkMmTn6Szee9BBnZqyi/O785pXapOgJjZAncPlaVv1T3NQESqvLyCQibPz2DsJ2lsz86jb/vGPHjFiZzZtbkOYR0DBYmIVDmHCop4bUEG/5iRxpZ9uYQ6NOGRq/pyRtfkWwerMihIRKTKOHiokCkLM/nnrHQy9xykX0pjHrziJM7qpj2QaChIRCTp5eQV8K85G3k6WMr9pHaNeOAyncZbXhQkIpK0cvML+decjYybmc7unEOc1a05Pz23KwM7NVWAlCMFiYgkna/zCnhl7ibGf7aOnfvzOLNrc35xQXcGdEjuVXhjRUEiIkkjOzefF7/cwDOfr2fvgXxO69yMJ67pxyBdB1KhFCQikvD2Hcznmc/W8fwXG/g6r4DzerbkjiHd6Nu+caxLqxIUJCKSsPYdzOe5z9fz3Ofr2Z9XwMUnHs9PBnelT9tGsS6tSlGQiEjC+TqvgOc+X8/Tn65jf14Bw3ofz+1DutK7jQIkFhQkIpIwcvMLmTh7I+NmpZOVc4gLe7XiZ+d3U4DEmIJEROLeoYIiJqdm8MSMtWzPzuOsbs355YU9NAcSJxQkIhK3Couctxdt5tGP1pCRdZBQhyY8NkJnYcUbBYmIxJ2iIuf95dv434/WsGb71/Ru05Dnf9iHwT10JXo8UpCISNxwd2au3snfPlzN8i3ZdGlRn39c25+L+uiWtvFMQSIicWHuut08/MFqUjfuIaVpPR656mQu69eW6gqQuKcgEZGYWpK5l4c/WM1na3fRqmFt/nR5H/4r1J6a1avFujQpJQWJiMTE2u37eeTDNby/fBtN6tXkdxefwA2ndaBOzeqxLk2OkYJERCrVpt0HeOzjtbz5VSb1atXg5+d3Y9SZnWhQp2asS5MyUpCISKXYsvcgT8xI47XUDKpXM350Rid+cm5XmtavFevSJEoKEhGpUDv25/LkJ+m8PHcTjnPtqSmMObcrrRrWiXVpUk6OGiRm9hxwKbDD3fsEbQ8D3wMOAenATe6+18w6AiuB1UH3Oe5+a9BnADABqAu8B/zM3d3MagMvAgOA3cDV7r4h6HMj8Pvgvf7o7i9EO2ARqRyb9x5k3Mw0Js/PpNCdqwa046fndaVdk3qxLk3KWWn2SCYAYwl/2BebDtzj7gVm9hBwD/Cb4LV0d+9bwvuMA0YDcwgHyTBgGjAK2OPuXc1sBPAQcLWZNQXuBUKAAwvMbKq77zm2IYpIZdqTc4inZqXz/BcbALhiQFtuObsLHZvXj21hUmGOGiTu/mmwpxHZ9mHE0znAlUd6DzNrDTR099nB8xeBywgHyXDgvmDTKcBYC1+6OhSY7u5ZQZ/phMPnlaPVLCKV78Ch8Iq8T81aR86hAn7Qrx13Xtidto3rxro0qWDlMUfyI+DViOedzOwrIBv4vbt/BrQFMiO2yQzaCL5nAAR7OPuAZpHtJfT5BjMbTXhvh5SUlGjHIyLHIDe/kBe+3MDTn61j19eHuKBXK351YQ96HN8g1qVJJYkqSMzsd0AB8FLQtBVIcffdwZzIW2bWGyjp0lQvfpvveO1Ifb7Z6D4eGA8QCoVK3EZEyld+YRGT5mfw+MdrI+6L3o0BHZrGujSpZGUOkmAi/FJgiLs7gLvnAXnB4wVmlg50J7w30S6ieztgS/A4E2gPZJpZDaARkBW0Dz6sz8yy1isi5Wfm6h3c/84K1u3M4ZSOTRh7TT9O1Yq8VVaZgsTMhhGeXD/H3Q9EtLcAsty90Mw6A92Ade6eZWb7zWwQMBcYCTwRdJsK3AjMJjzXMiM4m+sD4M9m1iTY7kLCk/oiEiNz1u3m0elrmLs+i07N6/P0yBDnn9BSK/JWcaU5/fcVwnsGzc0sk/CZVPcAtYHpwT+g4tN8zwbuN7MCoBC4tXiyHLiN/z/9d1rwBfAsMNHM0gjviYwACMLnAWB+sN39Ee8lIpVoxZZs/vzeSj5P20XLBrW573u9uPbUDtSqofWwBCw4KpU0QqGQp6amxroMkaSwYVcOf5++hqmLt9Cobk1uP68r1w/SeljJyMwWuHuoLH11ZbuIfMuO7Fwen7GWSfMyqFHd+MngLtxydhca1dN6WPJtChIR+Y99B/P556x0nvtiPQWFzjUDU7j9vK601HImcgQKEhHh4KFCXpi9gXEz09l3MJ/hfdtw5wXd6dBMV6PL0SlIRKqw/MIiJqdm8NhHa9mxP49ze7TgV0N70LtNo1iXJglEQSJSBRUVOe8u3cojH65mw+4DDOjQhCd0LYiUkYJEpApxdz5du4u/vr+K5Vuy6dGqAc+MDDFE14JIFBQkIlXEV5v28ND7q5izLot2Tery6NUn8/2T21K9mgJEoqMgEUlyG3fn8OC0VUxbto1m9Wvxh+/3ZsTA9tSuoWtBpHwoSESS1I7sXMZ+ksYr8zZRq3o1fjakGzef3ZnjauvXXsqX/kWJJJni+4KMm5nOocIirhzQjp+f3123tpUKoyARSRLuzrRl23jgnRVs3ZfLBb1a8buLT9CdCaXCKUhEksCKLdnc/85y5qzLolfrhjxxTT9CHXVfEKkcChKRBLY9O5dHPlzNawsyaVy3Jg8M7801A1OoUV2r8krlUZCIJKCcvALGf7qO8Z+uo6CoiFFndOL287ppUUWJCQWJSAIpLHJeS83gkelr2Lk/j0tOas1vhvYkpVm9WJcmVZiCRCQBuDuz1uzkL++tYvX2/Qzo0ISnrh/AgA5Njt5ZpIIpSETi3Iot2fxl2ko+W7uLDs3qMe66/gzrc7yWNJG4oSARiVPb9oUn0qcszKRR3Zr8z6W9uH6Qbm8r8UdBIhJncvIK+Oen6xj/aTpFRXDzWZ0ZM7irJtIlbilIROJEYZHz+sJM/vbBanbsz+PSk1rzm2E9ad9UE+kS3xQkInFgdvpuHnhnBSu2ZtMvpTHjNJEuCeSoB1vN7Dkz22FmyyLamprZdDNbG3xvEvHaPWaWZmarzWxoRPsAM1savPa4BTOFZlbbzF4N2ueaWceIPjcGP2Otmd1YbqMWiRMZWQcY8/JCrnl6DvsO5vPYiL68cdvpChFJKKWZtZsADDus7W7gY3fvBnwcPMfMegEjgN5BnyfNrHit6nHAaKBb8FX8nqOAPe7eFXgUeCh4r6bAvcCpwEDg3sjAEklkX+cV8PAHqxjyyCw+WrGdX5zfnY9/eQ7D+7bV2ViScI56aMvdP43cSwgMBwYHj18AZgK/CdonuXsesN7M0oCBZrYBaOjuswHM7EXgMmBa0Oe+4L2mAGODvZWhwHR3zwr6TCccPq8c+zBF4sOhgiImztnIEzPWsvdAPpf3a8uvh/WgdaO6sS5NpMzKOkfSyt23Arj7VjNrGbS3BeZEbJcZtOUHjw9vL+6TEbxXgZntA5pFtpfQ5xvMbDThvR1SUlLKOCSRiuPufLxyB396byXrd+VwVrfm3DW0Bye1axzr0kSiVt6T7SXtk/sR2sva55uN7uOB8QChUKjEbURiZfPeg9w3dTnTV2ync/P6PH/TKQzu3kKHsCRplDVItptZ62BvpDWwI2jPBNpHbNcO2BK0tyuhPbJPppnVABoBWUH74MP6zCxjvSKVLjs3n8c+Wsu/5mzEDO65qCejzuyklXkl6ZT1X/RUoPgsqhuBtyPaRwRnYnUiPKk+LzgMtt/MBgXzHyMP61P8XlcCM9zdgQ+AC82sSTDJfmHQJhLX3J13l2xlyCOzeP6L9Xzv5DZ8/MvB3HJOF4WIJKWj7pGY2SuE9wyam1km4TOpHgQmm9koYBNwFYC7LzezycAKoAAY4+6FwVvdRvgMsLqEJ9mnBe3PAhODifkswmd94e5ZZvYAMD/Y7v7iiXeReJW6IYsH3lnB4sx99G7TkGdvDGkeRJKehf/4Tx6hUMhTU1NjXYZUMTv25/Lge6t446vNtGlUh5+f350f9G+rPRBJGGa2wN1DZemrK9tFolBY5Lw6P4OH3l/FwUOFjDm3C2PO7Uq9WvrVkqpD/9pFymjBxj387s2lrNq2n4GdmvKXH5xIlxbHxboskUqnIBE5Rjv25/LX91czZUEmbRrV4R/X9ufiE3V/EKm6FCQipZRfWMSLszfy6PQ15BUUcss5nbn9vG4cV1u/RlK16TdApBQ+XL6Nv0xbxfpdOZzdvQV/+H5vOjWvH+uyROKCgkTkCDKyDnDv1OXMWLWD7q2O49kbQ5zXs6UOY4lEUJCIlCA3v5B/zlrHkzPTqFHN+O3FPbnpjE7U1Om8It+iIBE5zKdrdnLPG0vZvPcgl5zYmt9dcgJtGmt1XpHvoiARCezIzuWP765k6uItdG15HK/cPIjTujSLdVkicU9BIlVeQXA21t+nr+FQQRE/G9KN2wZ3oU7N6kfvLCIKEqnaFmzcw+/fWsbKrdmc3b0F93+/Nx11NpbIMVGQSJW0J+cQD72/iknzMzi+YR3GXdefYX10UaFIWShIpEpxd15LzeQv01aSnVvA6LM7c8cQXVQoEg399kiVkb7za3735lLmrMvilI5NeOCyPvQ8vmGsyxJJeAoSSXp5BYWMm5nOk5+kU6dmNf58+YmMOKU91arpMJZIeVCQSFKbnb6b3725lHW7chjetw2/v6QXLRrUjnVZIklFQSJJaU/OIf747kpeX5hJStN6vPijgZzdvUWsyxJJSgoSSSruzptfbeaP764k+2A+Y87twu3nddM1ISIVSEEiSSN959f84d8r+HTNTvqnNOZPl5/ICa01mS5S0RQkkvAOHirksY/X8sxn66hbqzr/fWkvbjq9oybTRSqJgkQS2vQV27n/neVkZB3kqgHt+PWwnppMF6lkZV4T28x6mNmiiK9sM/u5md1nZpsj2i+O6HOPmaWZ2WozGxrRPsDMlgavPW7B5cVmVtvMXg3a55pZx6hGK0lj676D3DIxlZtfTKVOjeq8OnoQD191skJEJAbKvEfi7quBvgBmVh3YDLwJ3AQ86u5/i9zezHoBI4DeQBvgIzPr7u6FwDhgNDAHeA8YBkwDRgF73L2rmY0AHgKuLmvNkviKipxJ8zP483srKSgq4q6hPRh9dmfdJ0Qkhsrr0NYQIN3dNx5hraLhwCR3zwPWm1kaMNDMNgAN3X02gJm9CFxGOEiGA/cF/acAY83M3N3LqW5JIOt35XD360uYuz6L0zo348ErTqRDMy2wKBJr5RUkI4BXIp7/1MxGAqnAL919D9CW8B5HscygLT94fHg7wfcMAHcvMLN9QDNgV+QPN7PRhPdoSElJKachSbwoKCzi2c/X8/fpa6hVoxoP/uBErj6lvRZYFIkTUR8PMLNawPeB14KmcUAXwoe9tgKPFG9aQnc/QvuR+nyzwX28u4fcPdSihS46SyartmXzg3Ff8pdpqzinews+vvMcRgxMUYiIxJHy2CO5CFjo7tsBir8DmNnTwDvB00ygfUS/dsCWoL1dCe2RfTLNrAbQCMgqh5olzh0qKGLczHTGfrKWhnVqMvbaflxyYmsFiEgcKo8ZymuIOKxlZq0jXrscWBY8ngqMCM7E6gR0A+a5+1Zgv5kNCs7WGgm8HdHnxuDxlcAMzY8kv6WZ+/j+2M959KM1XHxia6bfeQ6XntRGISISp6LaIzGzesAFwC0RzX81s76ED0FtKH7N3Zeb2WRgBVAAjAnO2AK4DZgA1CU8yT4taH8WmBhMzGcRnouRJJWbH76wcPyn62hWvxZPjwxxQa9WsS5LRI7Cku0P/FAo5KmpqbEuQ47Rgo1Z3DVlCet25nB1qD2/veQEGtWtGeuyRKoMM1vg7qGy9NWV7RJTBw4V8PAHq5nw5QbaNKqrVXpFEpCCRGJm7rrd3DVlCZuyDjDytA78elhP3fJWJAHpt1Yq3f7cfB6ctoqX5m6iQ7N6vDp6EKd2bhbrskSkjBQkUqk+W7uT30xZwrbsXEad2Yk7L+hOfe2FiCQ0/QZLpcjJK+DBaauYOGcjXVrUZ8ptp9M/pUmsyxKRcqAgkQo3b30Wv3ptMRl7DjDqzE7cNbSH7lgokkQUJFJhDhUUMXbGWp74JI32Terx6ujTGNipaazLEpFypiCRCpGRdYCfvryQxZn7uKJ/O+4f3ltzISJJSr/ZUu7e+moz//3WMjAYd11/Ljqx9dE7iUjCUpBIudl3MJ/7/72C1xdmEurQhEev7kv7pvViXZaIVDAFiZSLmat38Ns3lrItO5c7zuvKHUO6UUN3LRSpEhQkEpX9ufn86d2VTJqfQbeWx/HGT86gb/vGsS5LRCqRgkTKbNaandz9+hK2Z+dyy9md+cUF3XVar0gVpCCRY5aTV8Af313BK/My6NryOF6/7XT66eJCkSpLQSLHZMHGLO6cvJhNWQe45ZzO/OJ87YWIVHUKEimVwiJn7Iw0Hvt4DW0a12XSzVpoUUTCFCRyVJl7DnDnq4uZtyGLy/u15YHL+mi5dxH5D30ayBG9v2wbd01ZTFGR8/f/Opkf9G8X65JEJM4oSKREeQWF/OW9VUz4cgMnt2vEE9f0J6WZLi4UkW9TkMi3bNp9gDEvL2Tp5n386IxO3H1RT2rV0MWFIlIyBYl8w7SlW/n1lCWYwfgbBnBh7+NjXZKIxLmo/sw0sw1mttTMFplZatDW1Mymm9na4HuTiO3vMbM0M1ttZkMj2gcE75NmZo+bmQXttc3s1aB9rpl1jKZe+W55BYXc+/YybntpIV1aHse7d5ylEBGRUimP4xXnuntfdw8Fz+8GPnb3bsDHwXPMrBcwAugNDAOeNLPiCxDGAaOBbsHXsKB9FLDH3bsCjwIPlUO9cpiNu3O4YtyXvDB7Izef1YnJt5ymxRZFpNQq4sD3cOCF4PELwGUR7ZPcPc/d1wNpwEAzaw00dPfZ7u7Ai4f1KX6vKcCQ4r0VKR/vLtnKpY9/TkbWQZ4ZGeJ3l/TSfIiIHJNo50gc+NDMHPinu48HWrn7VgB332pmLYNt2wJzIvpmBm35wePD24v7ZATvVWBm+4BmwK4o667ycvML+eO7K/jXnE30S2nM2Gv707Zx3ViXJSIJKNogOcPdtwRhMd3MVh1h25L2JPwI7Ufq8803NhtN+NAYKSkpR65YWL8rhzEvLWTF1mxuObszvxrag5pa8l1EyiiqIHH3LcH3HWb2JjAQ2G5mrYO9kdbAjmDzTKB9RPd2wJagvV0J7ZF9Ms2sBtAIyCqhjvHAeIBQKPStoJH/N3XxFu55fQk1a1TjuR+GOK9nq1iXJCIJrsx/hppZfTNrUPwYuBBYBkwFbgw2uxF4O3g8FRgRnInVifCk+rzgMNh+MxsUzH+MPKxP8XtdCcwI5lHkGOXmF/LbN5dyxytfcULrhrx3x1kKEREpF9HskbQC3gzmvmsAL7v7+2Y2H5hsZqOATcBVAO6+3MwmAyuAAmCMuxcG73UbMAGoC0wLvgCeBSaaWRrhPZERUdRbZaXv/JoxLy1k1bb93Da4C3de0F2HskSk3Fiy/YEfCoU8NTU11mXEjbcXbea3byylVo1q/P3qvpzbo+XRO4lIlWNmCyIu4zgmurI9SeUXFvGnd1cy4csNnNKxCY9f04/WjXRWloiUPwVJEtqRncuYlxcyf8MeRp3ZiXsu6kkNHcoSkQqiIEkyqRuy+MlLC/k6r4DHRvRleN+2R+8kIhIFBUmScHcmztnIH/69gnZN6jLhpoH0atMw1mWJSBWgIEkC+YVF3Dt1OS/P3cSQni15dERfGtapGeuyRKSKUJAkuKycQ9z2rwXMXZ/Fred04a6hPaheTcuRiUjlUZAksNXb9vPjF+ezPTuPR68+mcv76Ta4IlL5FCQJavqK7fx80lfUq12DV0cPol9Kk6N3EhGpAAqSBOPujJuVzsMfrKZPm0aMHzlA14eISEwpSBJIbn4hd7++hLcWbeHSk1rz8JUnU7dW9aN3FBGpQAqSBLEjO5ebJy5gccZefnVhd8ac2xXd40tE4oGCJAEszdzHj1+cz/7cAp66fgDD+uhe6iISPxQkce6D5dv42aSvaFa/Nq/fdjontNZFhiISXxQkcWzCF+v5wzsrOKldY54ZGaJFg9qxLklE5FsUJHHI3Xns47X870drubBXKx4b0U+T6iIStxQkcaaoyHng3RU8/8UGrujfjoeuOFEr94pIXFOQxJGCwiLufmMpUxZkctMZHfnvS3pRTcudiEicU5DEidz8Qu545Ss+XLGdX5zfnTuG6PReEUkMCpI4kJNXwOiJqXyRtpt7v9eLm87oFOuSRERKTUESY3sPHOKHz89n6eZ9PHLVyVwxQAsvikhiUZDE0I7sXG54dh7rd+Xw5HX9GdpbFxqKSOJRkMRIRtYBrntmLru+zuP5m07hjK7NY12SiEiZlPm8UjNrb2afmNlKM1tuZj8L2u8zs81mtij4ujiizz1mlmZmq81saET7ADNbGrz2uAWzzGZW28xeDdrnmlnHKMYaN9Zs388V475k38F8XvrxqQoREUlo0VygUAD80t1PAAYBY8ysV/Dao+7eN/h6DyB4bQTQGxgGPGlmxVfZjQNGA92Cr2FB+yhgj7t3BR4FHoqi3riwOGMv//XP2QBMvuU03UdERBJemYPE3be6+8Lg8X5gJdD2CF2GA5PcPc/d1wNpwEAzaw00dPfZ7u7Ai8BlEX1eCB5PAYZYAp8T+2X6Lq59eg4N6tRgyq2n0+P4BrEuSUQkauVyyXRwyKkfMDdo+qmZLTGz58ys+E/utkBGRLfMoK1t8Pjw9m/0cfcCYB/QrISfP9rMUs0sdefOneUxpHL34fJt/PD5+bRtUpcpt55OSrN6sS5JRKRcRB0kZnYc8Drwc3fPJnyYqgvQF9gKPFK8aQnd/QjtR+rzzQb38e4ecvdQixYtjm0AleCNhZnc9tJCTmjdkFdHn0arhnViXZKISLmJKkjMrCbhEHnJ3d8AcPft7l7o7kXA08DAYPNMoH1E93bAlqC9XQnt3+hjZjWARkBWNDVXtknzNnHn5MWc2qkpL/34VJrUrxXrkkREylU0Z20Z8Cyw0t3/HtHeOmKzy4FlweOpwIjgTKxOhCfV57n7VmC/mQ0K3nMk8HZEnxuDx1cCM4J5lITwyrxN3P3GUs7p3oLnfngKx9XW2dYiknyi+WQ7A7gBWGpmi4K23wLXmFlfwoegNgC3ALj7cjObDKwgfMbXGHcvDPrdBkwA6gLTgi8IB9VEM0sjvCcyIop6K9XEORv577eWMbhHC566fgB1amoZeBFJTpZAf+CXSigU8tTU1JjWUBwiQ3q25Mnr+1O7hkJEROKbmS1w91BZ+upYSzl7LTXjPyEy7voB1Kqhe4mISHLTp1w5+vfiLfzm9SWc1a05T17fXyEiIlWCPunKySerdvCLVxcR6tiU8TeEdDhLRKoMBUk5SN2QxW0vLeCE1g159saQ7q8uIlWKgiRKK7dm86MJ82nTqC4TbjqFBnVqxrokEZFKpSCJwvpdOYx8bh71atVg4o9PpdlxtWNdkohIpVOQlNGO7Fyuf2YuhUXOv348kLaN68a6JBGRmFCQlMHBQ4WMeiGVPQcOMeGmU+jaUqv4ikjVpetIjpG7c9eUxSzbso+nbwhxUrvGsS5JRCSmtEdyjP7xSRrvLNnKr4f25PxerWJdjohIzClIjsEHy7fxtw/XcHm/ttx6TudYlyMiEhcUJKW0cms2v3h1ESe3b8xffnAiCXyjRhGRcqUgKYW9Bw5x84upNKhTg/E3aCVfEZFImmw/ivzCIsa8vJAd2Xm8essg3d1QROQwCpKjeHT6Gr5I283DV55Ev5QmR+8gIlLF6NDWEcxO3824WelcHWrPVaH2R+8gIlIFKUi+w74D+dw5eREdm9Xnf77XK9bliIjELR3a+g5/eGc5O/bn8eZPTqe+7rUuIvKdtEdSgi/TdvHGws3cek5nXbkuInIUCpLD5BUU8vu3l5HStB63n9ct1uWIiMQ9HbM5zDOfrWfdzhyev+kUXS8iIlIKCbFHYmbDzGy1maWZ2d0V9XP2HcznqZnpXNCrFef2aFlRP0ZEJKnEfZCYWXXgH8BFQC/gGjOrkNOoJs7ewP68An42RIe0RERKK+6DBBgIpLn7Onc/BEwChpf3D8nJK+DZz9czpGdL+rRtVN5vLyKStBIhSNoCGRHPM4O2/zCz0WaWamapO3fuLNMP+TqvgNO6NGPMeV3LXqmISBWUCJPtJS2z69944j4eGA8QCoW8hO2PqlXDOjx53YCydBURqdISYY8kE4hcn6QdsCVGtYiIyGESIUjmA93MrJOZ1QJGAFNjXJOIiATi/tCWuxeY2U+BD4DqwHPuvjzGZYmISCDugwTA3d8D3ot1HSIi8m2JcGhLRETimIJERESioiAREZGoKEhERCQq5l6m6/filpntBDZG8RbNgV3lVE4iqsrjr8pjB42/qo+/h7s3KEvHhDhr61i4e4to+ptZqruHyqueRFOVx1+Vxw4av8ZvqWXtq0NbIiISFQWJiIhERUHybeNjXUCMVeXxV+Wxg8av8ZdR0k22i4hI5dIeiYiIREVBIiIiUamSQWJmw8xstZmlmdndJbxuZvZ48PoSM+sfizorSinGf10w7iVm9qWZnRyLOivK0cYfsd0pZlZoZldWZn0VrTTjN7PBZrbIzJab2azKrrEileLffyMz+7eZLQ7Gf1Ms6qwIZvacme0ws2Xf8XrZPvvcvUp9EV6KPh3oDNQCFgO9DtvmYmAa4bszDgLmxrruSh7/6UCT4PFFVW38EdvNILzq9JWxrruS//83BlYAKcHzlrGuu5LH/1vgoeBxCyALqBXr2stp/GcD/YFl3/F6mT77quIeyUAgzd3XufshYBIw/LBthgMvetgcoLGZta7sQivIUcfv7l+6+57g6RzCd6VMFqX5/w9wO/A6sKMyi6sEpRn/tcAb7r4JwN2T6b9BacbvQAMzM+A4wkFSULllVgx3/5TweL5LmT77qmKQtAUyIp5nBm3Huk2iOtaxjSL8F0qyOOr4zawtcDnwVCXWVVlK8/+/O9DEzGaa2QIzG1lp1VW80ox/LHAC4Vt6LwV+5u5FlVNezJXpsy/plkgpBSuh7fBzoEuzTaIq9djM7FzCQXJmhVZUuUoz/v8FfuPuheE/SpNKacZfAxgADAHqArPNbI67r6no4ipBacY/FFgEnAd0Aaab2Wfunl3BtcWDMn32VcUgyQTaRzxvR/gvj2PdJlGVamxmdhLwDHCRu++upNoqQ2nGHwImBSHSHLjYzArc/a1KqbBilfbf/y53zwFyzOxT4GQgGYKkNOO/CXjQw5MGaWa2HugJzKucEmOqTJ99VfHQ1nygm5l1MrNawAhg6mHbTAVGBmcwDAL2ufvWyi60ghx1/GaWArwB3JAkf4VGOur43b2Tu3d0947AFOAnSRIiULp//28DZ5lZDTOrB5wKrKzkOitKaca/ifDeGGbWCugBrKvUKmOnTJ99VW6PxN0LzOynwAeEz+B4zt2Xm9mtwetPET5T52IgDThA+C+UpFDK8f8P0Ax4MvirvMCTZFXUUo4/aZVm/O6+0szeB5YARcAz7l7i6aKJppT//x8AJpjZUsKHen7j7kmxvLyZvQIMBpqbWSZwL1ATovvs0xIpIiISlap4aEtERMqRgkRERKKiIBERkagoSEREJCoKEhGRBHe0xRhL2P6/zGxFsCjly1H/fJ21JSKS2MzsbOBrwutk9TnKtt2AycB57r7HzFpGu56a9khERBJcSYsxmlkXM3s/WC/tMzPrGbx0M/CP4oVZy2NRTgWJiEhyGg/c7u4DgF8BTwbt3YHuZvaFmc0xs2HR/qAqd2W7iEiyM7PjCN9X6LWIhUdrB99rAN0IX+HeDvjMzPq4+96y/jwFiYhI8qkG7HX3viW8lgnMcfd8YL2ZrSYcLPOj+WEiIpJEgiXv15vZVfCfW+gW3zL7LeDcoL054UNdUS1KqSAREUlwwWKMs4EeZpZpZqOA64BRZrYYWM7/3wnyA2C3ma0APgHuivZWETr9V0REoqI9EhERiYqCREREoqIgERGRqChIREQkKgoSERGJioJERESioiAREZGo/B9WQez2xrHzfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_tokens, n_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Unicorn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (как написано выше)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29231\n",
      "    positive       0.76      0.79      0.78     27478\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "У каждого слова есть лемма (нормальная форма):\n",
    "\n",
    "    кошке, кошку, кошкам, кошкой ⟹ кошка\n",
    "    бежал, бежит, бегу ⟹ бежать\n",
    "    белому, белым, белыми ⟹ белый\n",
    "\n",
    "\n",
    "**Лемматизация** – это приведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (1.24.2)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь использовать лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "stopwords_ru.update([' ', '\\n'])\n",
    "\n",
    "def my_preproc(text, stopwords = stopwords_ru):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.74      0.76     29416\n",
      "    positive       0.73      0.77      0.75     27293\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый, с большим количеством функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте напишем аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Лучше всего пользоваться линуксом*, mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'Действительно, на его лице не отражалось никаких чувств – ни проблеска сочувствия не было на нем, а ведь боль просто невыносима'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на он лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на нем, а ведь боль просто невыносимый\n"
     ]
    }
   ],
   "source": [
    "lemmas1 = [pymorphy2_analyzer.parse(word)[0].normal_form for word in sent1.split()]\n",
    "print(' '.join(lemmas1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на его лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на немой, а ведь боль просто невыносимый\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmas2 = mystem_analyzer.lemmatize(sent1)\n",
    "print(''.join(lemmas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Стемминг\n",
    "\n",
    "Слова состоят из морфем: 𝑤𝑜𝑟𝑑=𝑠𝑡𝑒𝑚+𝑎𝑓𝑓𝑖𝑥𝑒𝑠. Стемминг позволяет отбросить аффиксы. Чаще всего используется алгоритм Портера.\n",
    "\n",
    "Алгоритм Портера состоит из 5 циклов команд, на каждом цикле – операция удаления / замены суффикса. Возможны вероятностные расширения алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределен\n",
      "пристав\n",
      "сдела\n",
      "словообразован\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "words = ['распределение', 'приставить', 'сделала', 'словообразование']\n",
    "for w in words:\n",
    "    stem = stemmer.stem(w)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27997\n",
      "    positive       1.00      1.00      1.00     28712\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоило оставить пунктуацию -- и все метрики равны 1! Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32916\n",
      "    positive       0.83      1.00      0.91     23793\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.92      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = \n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      1.00     27667\n",
      "   positive       1.00      0.99      1.00     29042\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы оказываются очень значимыми.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сегментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знаки \".\", \"?\", \"!\" не всегда однозначно определяют границы предложений.\n",
    "\n",
    "Бинарный классификатор для сегментации предложений: для каждой точки \".\" определить, является ли она концом предложения или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rusenttokenize\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Installing collected packages: rusenttokenize\n",
      "Successfully installed rusenttokenize-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install rusenttokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Эта шоколадка за 400р.\n",
      "ничего из себя не представляла.\n",
      "В г.\n",
      "2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.\n",
      "\n",
      "3\n",
      "Эта шоколадка за 400р. ничего из себя не представляла.\n",
      "В г. 2019 Артём решил больше не ходить в этот магазин на берегу р.\n",
      "Москвы.\n"
     ]
    }
   ],
   "source": [
    "text = 'Эта шоколадка за 400р. ничего из себя не представляла. В г. 2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.'\n",
    "\n",
    "\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')\n",
    "\n",
    "print()\n",
    "sents = ru_sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения\n",
    "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Классы символов:*__\n",
    "\n",
    "__[A-Z]__ – символы верхнего регистра (латиница)\n",
    "\n",
    "__[a-z]__ – символы нижнего регистра (латиница)\n",
    "\n",
    "__[А-Я]__ – символы верхнего регистра (кириллица)\n",
    "\n",
    "__[а-я]__ – символы нижнего регистра (кириллица)\n",
    "\n",
    "__[0-9]__ или __\\d__ – цифра\n",
    "\n",
    "__[^0-9]__ или __\\D__ – любой символ, кроме цифры\n",
    "\n",
    "__.__ – любой символ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Служебные символы:*__\n",
    "\n",
    "__\\t__ – табуляция\n",
    "\n",
    "__\\s__ – любой пробельный символ\n",
    "\n",
    "__\\S__ – все символы, кроме пробельных\n",
    "\n",
    "__\\n__ – перенос строки\n",
    "\n",
    "__^__ – начало строки\n",
    "\n",
    "__$__ – конец строки\n",
    "\n",
    "__\\__ – экранирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Операторы:*__\n",
    "\n",
    "__?__ - предыдущий символ/группа может быть, а может не быть\n",
    "\n",
    "__+__ - предыдущий символ/группа может повторяться 1 и более раз\n",
    "\n",
    "__*__ - предыдущий символ/группа может повторяться 0 и более раз\n",
    "\n",
    "__{n,m}__ - предыдущий символ/группа может повторяться от от n до m включительно\n",
    "\n",
    "__{n,}__ - предыдущий символ/группа в скобках может повторяться n и более раз\n",
    "\n",
    "__{,m}__ - предыдущий символ/группа может повторяться до m раз\n",
    "\n",
    "__{n}__ - предыдущий символ/группа повторяется n раз\n",
    "\n",
    "Внутри групп не работают операторы __.__, __+__, __*__, их необходимо экранировать с помощью обратного слеша: \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Кот сидит на столе'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая убирает url из строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
